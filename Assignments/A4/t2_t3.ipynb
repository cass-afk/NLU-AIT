{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccc2fa97-980a-4e39-9670-f519811e2dd4",
   "metadata": {},
   "source": [
    "Reference Code: https://www.pinecone.io/learn/series/nlp/train-sentence-transformers-softmax/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a221f6c-a0f9-4f8f-9d96-7253ebfa3506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import re\n",
    "from   random import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import datasets\n",
    "import numpy as np\n",
    "\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6519600c-aba5-4935-ae7a-3bb304d81467",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3da707-96c6-42a3-9390-b6e00239ac3b",
   "metadata": {},
   "source": [
    "# 1.Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c02c5-c609-4e3f-8d4b-de816df6b534",
   "metadata": {},
   "source": [
    "## Train, Test, Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc021b16-7e6b-4b2d-a438-18f865ce698c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'premise': Value(dtype='string', id=None),\n",
       "  'hypothesis': Value(dtype='string', id=None),\n",
       "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n",
       "  'idx': Value(dtype='int32', id=None)},\n",
       " {'premise': Value(dtype='string', id=None),\n",
       "  'hypothesis': Value(dtype='string', id=None),\n",
       "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli = datasets.load_dataset('snli')\n",
    "mnli = datasets.load_dataset('glue', 'mnli')\n",
    "mnli['train'].features, snli['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e96d6bc-6e9e-467d-a7ce-caf6557ec7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of datasets to remove 'idx' column from\n",
    "mnli.column_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4cfc3a-be53-4283-8cdd-ca19961b1356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "    num_rows: 392702\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd214dc4-7601-4eb5-b138-e4b45aa6868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'idx' column from each dataset\n",
    "for column_names in mnli.column_names.keys():\n",
    "    mnli[column_names] = mnli[column_names].remove_columns('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5946b4-e155-4350-9d05-0976eb4145d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli.column_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeae5780-240d-417b-9ad8-39e7203cd2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 550152\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140752e7-2d61-41b2-992c-ffca6fc3078e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([-1,  0,  1,  2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46cbd2b5-a7b3-4db6-b10e-2fd79f24bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are -1 values in the label feature, these are where no class could be decided so we remove\n",
    "snli = snli.filter(\n",
    "    lambda x: 0 if x['label'] == -1 else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af8ddcca-a44b-4c8f-b082-17d798284890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([0, 1, 2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80bf02bc-c01a-4d3a-8935-3ed79e6a0f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "# Merge the two DatasetDict objects\n",
    "raw_dataset = DatasetDict({\n",
    "    'train': datasets.concatenate_datasets([snli['train'], mnli['train']]).shuffle(seed=55).select(list(range(1000))),\n",
    "    'test': datasets.concatenate_datasets([snli['test'], mnli['test_mismatched']]).shuffle(seed=55).select(list(range(100))),\n",
    "    'validation': datasets.concatenate_datasets([snli['validation'], mnli['validation_mismatched']]).shuffle(seed=55).select(list(range(1000)))\n",
    "})\n",
    "#remove .select(list(range(1000))) in order to use full dataset\n",
    "# Now, merged_dataset_dict contains the combined datasets from snli and mnli\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60277e3f-e739-4d7e-9bf5-5477786c1207",
   "metadata": {},
   "source": [
    "# 2.Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "960eb059-9cb2-4b0b-89d7-889848c75d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125002/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f8c7c6e-0cca-43f4-b328-725976a421f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    max_seq_length = 128\n",
    "    padding = 'max_length'\n",
    "    # Tokenize the premise\n",
    "    premise_result = tokenizer(\n",
    "        examples['premise'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    #num_rows, max_seq_length\n",
    "    # Tokenize the hypothesis\n",
    "    hypothesis_result = tokenizer(\n",
    "        examples['hypothesis'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    #num_rows, max_seq_length\n",
    "    # Extract labels\n",
    "    labels = examples[\"label\"]\n",
    "    #num_rows\n",
    "    return {\n",
    "        \"premise_input_ids\": premise_result[\"input_ids\"],\n",
    "        \"premise_attention_mask\": premise_result[\"attention_mask\"],\n",
    "        \"hypothesis_input_ids\": hypothesis_result[\"input_ids\"],\n",
    "        \"hypothesis_attention_mask\": hypothesis_result[\"attention_mask\"],\n",
    "        \"labels\" : labels\n",
    "    }\n",
    "\n",
    "tokenized_datasets = raw_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['premise','hypothesis','label'])\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc476099-21a5-49ff-a3dc-43591badc488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc996ca-2087-4da4-adf7-916ba3bd1448",
   "metadata": {},
   "source": [
    "# 3. Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "150a215a-7ddb-4d8d-b970-7f460bf7c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# initialize the dataloader\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets['train'], \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets['validation'], \n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets['test'], \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ec35acf-35a2-4dc7-9208-fe2972ad6886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch['premise_input_ids'].shape)\n",
    "    print(batch['premise_attention_mask'].shape)\n",
    "    print(batch['hypothesis_input_ids'].shape)\n",
    "    print(batch['hypothesis_attention_mask'].shape)\n",
    "    print(batch['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a17d8e-faba-4161-85eb-4454ec00cdcc",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dfa5802-2356-4554-9bc2-7d8d9da32606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39080d39-a163-4cf3-b0b3-4ffb793263c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL FROM TASK 1\n",
    "load_path = 'model/model_bert.pth'\n",
    "params, state = torch.load(load_path)\n",
    "model = BERT(**params, device=device).to(device)\n",
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e0f0a2-6596-4df7-a29a-04ec1be3cb1b",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8927a2ea-8199-4212-b4dd-b0e97a7e8e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mean pooling function\n",
    "def mean_pool(token_embeds, attention_mask):\n",
    "    # reshape attention_mask to cover 768-dimension embeddings\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
    "        token_embeds.size()\n",
    "    ).float()\n",
    "    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n",
    "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n",
    "        in_mask.sum(1), min=1e-9\n",
    "    )\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa5abce-e451-4d75-9d01-79626b90b39c",
   "metadata": {},
   "source": [
    "# 5.Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d8ffd-12e6-433f-b1d8-9fab79161c2c",
   "metadata": {},
   "source": [
    "## LATER \n",
    "Classification Objective Function\n",
    "We concatenate the sentence embeddings \n",
    " and \n",
    " with the element-wise difference \n",
    " and multiply the result with the trainable weight \n",
    ":\n",
    "\n",
    "\n",
    "where \n",
    " is the dimension of the sentence embeddings and k the number of labels. We optimize cross-entropy loss. This structure is depicted in Figure 1.\n",
    "\n",
    "Regression Objective Function.\n",
    "The cosine similarity between the two sentence embeddings \n",
    " and \n",
    " is computed. We use means quared-error loss as the objective function.\n",
    "\n",
    "(Manhatten / Euclidean distance, semantically similar sentences can be found.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6a881a9-f393-41ec-86d4-8bb32550e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurations(u,v):\n",
    "    # build the |u-v| tensor\n",
    "    uv = torch.sub(u, v)   # batch_size,hidden_dim\n",
    "    uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "    \n",
    "    # concatenate u, v, |u-v|\n",
    "    x = torch.cat([u, v, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "    return x\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    dot_product = np.dot(u, v)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    similarity = dot_product / (norm_u * norm_v)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22707fce-40ab-4883-9c28-1b9f4157ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_head = torch.nn.Linear(768*3, 3).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "optimizer_classifier = torch.optim.Adam(classifier_head.parameters(), lr=2e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9566e9d-0bfc-4050-ac3e-39f1a077b273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_564470/928846991.py:12: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  scheduler.step()\n",
      "/tmp/ipykernel_564470/928846991.py:20: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  scheduler_classifier.step()\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# and setup a warmup for the first ~10% steps\n",
    "total_steps = int(len(raw_dataset) / batch_size)\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler.step()\n",
    "\n",
    "scheduler_classifier = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer_classifier, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler_classifier.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8634fcfc-8951-417e-834d-96e7c988f6af",
   "metadata": {},
   "source": [
    "# 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16fcb7be-0fc2-4cc6-aba5-5ce3c5321776",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3ee71f1-047c-43dc-b412-8f950b0cbc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04401d7d576b4fe3a534231521b3f04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | loss = 2.930530\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6d8d8e00f24c20bbb6ccd6e53cd69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | loss = 1.892005\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_epoch = 2\n",
    "# 1 epoch should be enough, increase if wanted\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    classifier_head.train()\n",
    "    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, leave=True)):\n",
    "        # zero all gradients on each new step\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_classifier.zero_grad()\n",
    "\n",
    "        # prepare batches and more all to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        segment_ids = torch.zeros(batch_size, max_seq_length, dtype=torch.int32).to(device)  # each input contains only one sentence hence we define them all as sentence '0'\n",
    "        label = batch['labels'].to(device)\n",
    "\n",
    "        # extract token embeddings from BERT at last_hidden_state\n",
    "        u_last_hidden_state = model.get_last_hidden_state(inputs_ids_a, segment_ids)\n",
    "        v_last_hidden_state = model.get_last_hidden_state(inputs_ids_b, segment_ids)\n",
    "\n",
    "        # get the mean pooled vectors\n",
    "        u_mean_pool = mean_pool(u_last_hidden_state, attention_a) # batch_size, hidden_dim\n",
    "        v_mean_pool = mean_pool(v_last_hidden_state, attention_b) # batch_size, hidden_dim\n",
    "\n",
    "        # build the |u-v| tensor\n",
    "        uv = torch.sub(u_mean_pool, v_mean_pool)   # batch_size,hidden_dim\n",
    "        uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "\n",
    "        # concatenate u, v, |u-v|\n",
    "        x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "\n",
    "        # process concatenated tensor through classifier_head\n",
    "        x = classifier_head(x) #batch_size, classifer\n",
    "\n",
    "        # calculate the 'softmax-loss' between predicted and true label\n",
    "        loss = criterion(x, label)\n",
    "\n",
    "        # using loss, calculate gradients and then optimizerize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_classifier.step()\n",
    "\n",
    "        scheduler.step() # update learning rate scheduler\n",
    "        scheduler_classifier.step()\n",
    "\n",
    "    print(f'Epoch: {epoch + 1} | loss = {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a452efea-6654-4613-8f35-fa50def9c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "predictions = []\n",
    "probabilities = []\n",
    "classes = [\"entailment\", \"neutral\", \"contradiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37533397-08d3-41f1-a9db-8bfe2d4e5ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.9983\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "classifier_head.eval()\n",
    "total_similarity = 0\n",
    "num_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        # Move batches to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        segment_ids = torch.zeros(inputs_ids_a.shape[0], inputs_ids_a.shape[1], dtype=torch.int32).to(device)\n",
    "        label = batch['labels'].to(device)\n",
    "\n",
    "        # Extract token embeddings from BERT\n",
    "        u = model.get_last_hidden_state(inputs_ids_a, segment_ids)  # (batch_size, seq_len, hidden_dim)\n",
    "        v = model.get_last_hidden_state(inputs_ids_b, segment_ids)  # (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        # Get the mean pooled vectors\n",
    "        u_mean_pool = mean_pool(u, attention_a)  # (batch_size, hidden_dim)\n",
    "        v_mean_pool = mean_pool(v, attention_b)  # (batch_size, hidden_dim)\n",
    "\n",
    "        # Computing cosine similarity using PyTorch (more efficient)\n",
    "        similarity_scores = F.cosine_similarity(u_mean_pool, v_mean_pool, dim=-1)  # (batch_size,)\n",
    "        total_similarity += similarity_scores.sum().item()\n",
    "        num_samples += len(similarity_scores)\n",
    "\n",
    "        # Concatenate [u, v, |u - v|]\n",
    "        uv_abs = torch.abs(u_mean_pool - v_mean_pool)  # (batch_size, hidden_dim)\n",
    "        x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1)  # (batch_size, 3*hidden_dim)\n",
    "\n",
    "        # Classification\n",
    "        logit_fn = classifier_head(x)  # (batch_size, num_classes)\n",
    "        probs = F.softmax(logit_fn, dim=-1)\n",
    "        preds = torch.argmax(logit_fn, dim=-1)\n",
    "\n",
    "        labels.extend(label.cpu().tolist())\n",
    "        probabilities.extend(probs.cpu().tolist())\n",
    "        predictions.extend(preds.cpu().tolist())\n",
    "\n",
    "# Calculate average similarity\n",
    "average_similarity = total_similarity / num_samples\n",
    "print(f\"Average Cosine Similarity: {average_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c667f92-e57d-4103-9ac5-8dba90bb16a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.34      0.99      0.51       338\n",
      "      neutral       0.43      0.02      0.04       328\n",
      "contradiction       0.00      0.00      0.00       334\n",
      "\n",
      "     accuracy                           0.34      1000\n",
      "    macro avg       0.26      0.34      0.18      1000\n",
      " weighted avg       0.26      0.34      0.18      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125002/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/jupyter-st125002/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/jupyter-st125002/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels, predictions, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99ac9591-998c-4b17-b6cb-77df03c56342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "torch.save([model.params, model.state_dict()], 'model/sen_bert.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096aa7db-01a5-4061-ae5c-9fe5619b40ec",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abef1683-d510-452f-accb-84ba6e0e3d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(model, tokenizer, sentence_a, sentence_b, device):\n",
    "    # Tokenize and convert sentences to input IDs and attention masks\n",
    "    inputs_a = tokenizer(sentence_a, return_tensors='pt', max_length=max_seq_length, truncation=True, padding='max_length').to(device)\n",
    "    inputs_b = tokenizer(sentence_b, return_tensors='pt', max_length=max_seq_length, truncation=True, padding='max_length').to(device)\n",
    "\n",
    "    # Move input IDs and attention masks to the active device\n",
    "    inputs_ids_a = inputs_a['input_ids']\n",
    "    attention_a = inputs_a['attention_mask']\n",
    "    inputs_ids_b = inputs_b['input_ids']\n",
    "    attention_b = inputs_b['attention_mask']\n",
    "    segment_ids = torch.zeros(1, max_seq_length, dtype=torch.int32).to(device)\n",
    "\n",
    "    # Extract token embeddings from BERT\n",
    "    u = model.get_last_hidden_state(inputs_ids_a, segment_ids)\n",
    "    v = model.get_last_hidden_state(inputs_ids_b, segment_ids)\n",
    "\n",
    "    # Get the mean-pooled vectors\n",
    "    u_mean_pool = mean_pool(u, attention_a)  # (1, hidden_dim)\n",
    "    v_mean_pool = mean_pool(v, attention_b)  # (1, hidden_dim)\n",
    "\n",
    "    # Calculate cosine similarity using PyTorch\n",
    "    similarity_score = F.cosine_similarity(u_mean_pool, v_mean_pool, dim=-1).item()\n",
    "\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06c79757-8e4b-4ad0-80bb-de4fb850de30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9989\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "sentence_a = 'Your contribution helped make it possible for us to provide our students with a quality education.'\n",
    "sentence_b = \"Your contributions were of no help with our students' education.\"\n",
    "similarity = calculate_similarity(model, tokenizer, sentence_a, sentence_b, device)\n",
    "print(f\"Cosine Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af75c153-e126-4172-8258-693310995ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9989\n"
     ]
    }
   ],
   "source": [
    "sentence_a = 'An older man is drinking orange juice at a restaurant.'\n",
    "sentence_b = \"A man is drinking juice.\"\n",
    "similarity = calculate_similarity(model, tokenizer, sentence_a, sentence_b, device)\n",
    "print(f\"Cosine Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5c531a-4bb0-4e56-b66d-e2f5ed9c138c",
   "metadata": {},
   "source": [
    "# Task-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64e57608-d091-42a3-95da-501f161d2990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125002/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "pre_trained_model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb13b12d-6001-472a-b74a-aea6a1fdd0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78299428-31d8-43c4-b297-32c38b2bc3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sentence = [\"The cat is sleeping on the couch.\", \"The feline is resting on the sofa.\"]\n",
    "opp_sentence = [\"He is very punctual and reliable.\", \"You can never count on him to be on time.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c39ecbf-a86f-4410-a48c-257b1824a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(pos_sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_output = pre_trained_model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5409100-e8f7-4740-876a-1ada57f92b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73199284"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "sent_a_emb = sentence_embeddings[0].cpu().numpy().reshape(1, -1)\n",
    "sent_b_emb = sentence_embeddings[1].cpu().numpy().reshape(1, -1)\n",
    "cosine_similarity(sent_a_emb, sent_b_emb)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1cdd66c-401d-4726-aedc-4206ca6e4553",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(opp_sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_output = pre_trained_model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad8a8aa6-8e30-48e7-a300-0d74661b647f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48303467"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "sent_a_emb = sentence_embeddings[0].cpu().numpy().reshape(1, -1)\n",
    "sent_b_emb = sentence_embeddings[1].cpu().numpy().reshape(1, -1)\n",
    "cosine_similarity(sent_a_emb, sent_b_emb)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63037fad-282c-42f4-b195-1f6aafb1247f",
   "metadata": {},
   "source": [
    "# Evaluation of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60500505-f336-4ca4-87b1-f7ef4b57232e",
   "metadata": {},
   "source": [
    "## Evaluation of our model\n",
    "\n",
    "| Model Type  | Training Loss with SNLI and MNLI | Cosine Similarity(SNLI and MNLI) | Cosine Similarity (Similar Sentences) | Cosine Similarity (Dissimilar Sentences) |\n",
    "|------------|------------------------------|----------------------------------------------|--------------------------------------------------|--------------------------------------------------|\n",
    "| Custom model   | 1.89                        | 0.9983                                         | 0.9989                                             | 0.9989                                             |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569aedbe-d57f-4d8d-b407-0ab4a6092f4d",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "\n",
    "| Class          | Precision | Recall | F1-score | Support |\n",
    "|---------------|-----------|--------|----------|---------|\n",
    "| entailment    | 0.34      | 0.99   | 0.51     | 338     |\n",
    "| neutral       | 0.43      | 0.02   | 0.04     | 328     |\n",
    "| contradiction | 0.00      | 0.00   | 0.00     | 334     |\n",
    "| **Accuracy**  |           |        | **0.34** | 1000    |\n",
    "| **Macro Avg** | 0.26      | 0.34   | 0.18     | 1000    |\n",
    "| **Weighted Avg** | 0.26   | 0.34   | 0.18     | 1000    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6872c296-9d4a-46a5-8f18-b3b6ca09cfba",
   "metadata": {},
   "source": [
    "## Comparison of our model with pre-trained model\n",
    "\n",
    "| Model Type | Cosine Similarity (Similar sentence) | Cosine Similarity (Dissisimilar sentence) |\n",
    "|----------|----------|----------|\n",
    "| Our Model    | 0.9989    | 0.9989    |\n",
    "| Pre-trained    | 0.731     | 0.483     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5127b83d-1611-4087-a149-a8aa16f2bc98",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "Our custom model achieves a cosine similarity score of `0.9992` for similar sentences and `0.999` for dissimilar sentences. The fact that both values are almost identical indicates that the model fails to meaningfully differentiate between semantically similar and dissimilar sentence pairs. This suggests that the learned embeddings lack discriminative power and may have collapsed into highly similar vector representations regardless of semantic content. Such behavior is commonly associated with poor representation learning or overfitting to limited patterns in the training data.\n",
    "\n",
    "In contrast, the pre-trained model achieves a cosine similarity of `0.731` for similar sentences and `0.483` for dissimilar sentences. The clear separation between these two values demonstrates that the pre-trained model captures semantic relationships more effectively, producing embeddings that meaningfully distinguish similar from dissimilar inputs.\n",
    "\n",
    "Furthermore, the classification report reinforces this observation. Our custom model achieves an overall accuracy of `34%`, which is close to random guessing for a 3-class classification problem. The macro-average F1-score (`0.18`) and weighted-average F1-score (`0.18`) indicate consistently weak performance across all classes.\n",
    "\n",
    "Looking at the class-level performance:\n",
    "\n",
    "Entailment shows very high recall (`0.99`) but low precision (`0.34`), meaning the model predicts entailment for most samples, including many incorrect ones.\n",
    "\n",
    "Neutral has extremely low recall (`0.02`), indicating that the model almost never correctly identifies neutral cases.\n",
    "\n",
    "Contradiction has precision and recall of `0.00`, meaning the model completely fails to recognize contradiction instances.\n",
    "\n",
    "Overall, the results indicate that our custom model does not learn robust semantic representations and struggles to distinguish between classes. The pre-trained model, benefiting from large-scale pretraining, demonstrates significantly stronger semantic discrimination and generalization capability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cc85bb-e99c-4f7c-b8d3-128b5ddde1af",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "The implementation of BERT from scratch was carried out with reference to the professor’s provided notebook. The *Wikipedia* dataset from Hugging Face was used as the primary corpus for pretraining. Due to hardware limitations (RTX 2080 Ti with limited GPU memory), the dataset was reduced to approximately **100k samples** to make training feasible.\n",
    "\n",
    "During pretraining, several computational constraints were encountered. Large sequence lengths and batch sizes resulted in out-of-memory (OOM) errors. Consequently, the batch size was reduced to **3**, and the maximum sequence length was adjusted to a manageable size. Additionally, the number of training epochs was limited to avoid GPU memory crashes. Although initial attempts were made to train for a large number of epochs, the training loss plateaued while memory issues persisted, indicating diminishing returns from prolonged training under constrained resources.\n",
    "\n",
    "For **Task 2**, the model was fine-tuned on the SNLI and MNLI datasets to classify logical relationships between sentence pairs (*entailment*, *neutral*, *contradiction*). After preprocessing, the model was trained for **5 epochs**. Again, memory limitations required reducing the batch size from 32 to **8** in order to successfully complete training.\n",
    "\n",
    "During evaluation (**Task 3**), the performance of the custom model was significantly below expectations. The classification accuracy was **34%**, which is close to random guessing for a three-class problem (baseline ≈ 33%). The macro-average F1-score (**0.18**) and weighted-average F1-score (**0.18**) further confirm weak overall performance.\n",
    "\n",
    "## Class-level Analysis\n",
    "\n",
    "- **Entailment**: Very high recall (**0.99**) but low precision (**0.34**), indicating the model predicts entailment for most examples.\n",
    "- **Neutral**: Extremely low recall (**0.02**), meaning neutral cases are rarely identified correctly.\n",
    "- **Contradiction**: Precision and recall of **0.00**, indicating complete failure to recognize contradiction instances.\n",
    "\n",
    "Additionally, cosine similarity analysis shows that the custom model produces nearly identical similarity scores for similar (**0.9992**) and dissimilar (**0.999**) sentence pairs. This indicates poor semantic discrimination and suggests that the learned embeddings lack meaningful representational structure.\n",
    "\n",
    "In contrast, the pre-trained `all-mpnet-base-v2` model demonstrates clear separation between similar (**0.731**) and dissimilar (**0.483**) sentence pairs, reflecting significantly stronger semantic representation and generalization capability.\n",
    "\n",
    "\n",
    "\n",
    "## Challenges Faced\n",
    "\n",
    "- Limited GPU memory restricting batch size and sequence length  \n",
    "- Reduced dataset size compared to standard BERT pretraining  \n",
    "- Insufficient training scale for robust representation learning  \n",
    "- Difficulty achieving stable optimization from scratch  \n",
    "\n",
    "\n",
    "\n",
    "## Proposed Improvements\n",
    "\n",
    "To improve the performance of the custom model, the following enhancements are recommended:\n",
    "\n",
    "- Increase the size and diversity of the pretraining corpus  \n",
    "- Train for more epochs with stable memory management  \n",
    "- Use larger effective batch sizes via gradient accumulation  \n",
    "- Experiment with optimized learning rates and schedulers  \n",
    "- Increase model depth or hidden dimensions  \n",
    "- Apply mixed precision training to better utilize GPU memory  \n",
    "- Limit vocabulary size to reduce embedding dimensionality  \n",
    "\n",
    "\n",
    "\n",
    "In conclusion, the results highlight the substantial gap between training a transformer model from scratch under constrained resources and leveraging large-scale pre-trained models. Large-scale pretraining plays a critical role in learning meaningful and discriminative semantic representations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

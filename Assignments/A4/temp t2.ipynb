{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccc2fa97-980a-4e39-9670-f519811e2dd4",
   "metadata": {},
   "source": [
    "Reference Code: https://www.pinecone.io/learn/series/nlp/train-sentence-transformers-softmax/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a221f6c-a0f9-4f8f-9d96-7253ebfa3506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import re\n",
    "from   random import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import datasets\n",
    "import numpy as np\n",
    "\n",
    "# Set GPU device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6519600c-aba5-4935-ae7a-3bb304d81467",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3da707-96c6-42a3-9390-b6e00239ac3b",
   "metadata": {},
   "source": [
    "# 1.Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c02c5-c609-4e3f-8d4b-de816df6b534",
   "metadata": {},
   "source": [
    "## Train, Test, Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc021b16-7e6b-4b2d-a438-18f865ce698c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'premise': Value(dtype='string', id=None),\n",
       "  'hypothesis': Value(dtype='string', id=None),\n",
       "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n",
       "  'idx': Value(dtype='int32', id=None)},\n",
       " {'premise': Value(dtype='string', id=None),\n",
       "  'hypothesis': Value(dtype='string', id=None),\n",
       "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli = datasets.load_dataset('snli')\n",
    "mnli = datasets.load_dataset('glue', 'mnli')\n",
    "mnli['train'].features, snli['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e96d6bc-6e9e-467d-a7ce-caf6557ec7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of datasets to remove 'idx' column from\n",
    "mnli.column_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f4cfc3a-be53-4283-8cdd-ca19961b1356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "    num_rows: 392702\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd214dc4-7601-4eb5-b138-e4b45aa6868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'idx' column from each dataset\n",
    "for column_names in mnli.column_names.keys():\n",
    "    mnli[column_names] = mnli[column_names].remove_columns('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da5946b4-e155-4350-9d05-0976eb4145d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli.column_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeae5780-240d-417b-9ad8-39e7203cd2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 550152\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "140752e7-2d61-41b2-992c-ffca6fc3078e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([-1,  0,  1,  2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46cbd2b5-a7b3-4db6-b10e-2fd79f24bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are -1 values in the label feature, these are where no class could be decided so we remove\n",
    "snli = snli.filter(\n",
    "    lambda x: 0 if x['label'] == -1 else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8ddcca-a44b-4c8f-b082-17d798284890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([0, 1, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80bf02bc-c01a-4d3a-8935-3ed79e6a0f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "# Merge the two DatasetDict objects\n",
    "raw_dataset = DatasetDict({\n",
    "    'train': datasets.concatenate_datasets([snli['train'], mnli['train']]).shuffle(seed=55).select(list(range(1000))),\n",
    "    'test': datasets.concatenate_datasets([snli['test'], mnli['test_mismatched']]).shuffle(seed=55).select(list(range(100))),\n",
    "    'validation': datasets.concatenate_datasets([snli['validation'], mnli['validation_mismatched']]).shuffle(seed=55).select(list(range(1000)))\n",
    "})\n",
    "#remove .select(list(range(1000))) in order to use full dataset\n",
    "# Now, merged_dataset_dict contains the combined datasets from snli and mnli\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60277e3f-e739-4d7e-9bf5-5477786c1207",
   "metadata": {},
   "source": [
    "# 2.Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "960eb059-9cb2-4b0b-89d7-889848c75d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125002/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f8c7c6e-0cca-43f4-b328-725976a421f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    max_seq_length = 128\n",
    "    padding = 'max_length'\n",
    "    # Tokenize the premise\n",
    "    premise_result = tokenizer(\n",
    "        examples['premise'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    #num_rows, max_seq_length\n",
    "    # Tokenize the hypothesis\n",
    "    hypothesis_result = tokenizer(\n",
    "        examples['hypothesis'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    #num_rows, max_seq_length\n",
    "    # Extract labels\n",
    "    labels = examples[\"label\"]\n",
    "    #num_rows\n",
    "    return {\n",
    "        \"premise_input_ids\": premise_result[\"input_ids\"],\n",
    "        \"premise_attention_mask\": premise_result[\"attention_mask\"],\n",
    "        \"hypothesis_input_ids\": hypothesis_result[\"input_ids\"],\n",
    "        \"hypothesis_attention_mask\": hypothesis_result[\"attention_mask\"],\n",
    "        \"labels\" : labels\n",
    "    }\n",
    "\n",
    "tokenized_datasets = raw_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['premise','hypothesis','label'])\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc476099-21a5-49ff-a3dc-43591badc488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc996ca-2087-4da4-adf7-916ba3bd1448",
   "metadata": {},
   "source": [
    "# 3. Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "150a215a-7ddb-4d8d-b970-7f460bf7c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# initialize the dataloader\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets['train'], \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets['validation'], \n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets['test'], \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ec35acf-35a2-4dc7-9208-fe2972ad6886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch['premise_input_ids'].shape)\n",
    "    print(batch['premise_attention_mask'].shape)\n",
    "    print(batch['hypothesis_input_ids'].shape)\n",
    "    print(batch['hypothesis_attention_mask'].shape)\n",
    "    print(batch['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a17d8e-faba-4161-85eb-4454ec00cdcc",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dfa5802-2356-4554-9bc2-7d8d9da32606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39080d39-a163-4cf3-b0b3-4ffb793263c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL FROM TASK 1\n",
    "load_path = 'model/model_bert.pth'\n",
    "params, state = torch.load(load_path)\n",
    "model = BERT(**params, device=device).to(device)\n",
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e0f0a2-6596-4df7-a29a-04ec1be3cb1b",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8927a2ea-8199-4212-b4dd-b0e97a7e8e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mean pooling function\n",
    "def mean_pool(token_embeds, attention_mask):\n",
    "    # reshape attention_mask to cover 768-dimension embeddings\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
    "        token_embeds.size()\n",
    "    ).float()\n",
    "    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n",
    "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n",
    "        in_mask.sum(1), min=1e-9\n",
    "    )\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa5abce-e451-4d75-9d01-79626b90b39c",
   "metadata": {},
   "source": [
    "# 5.Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d8ffd-12e6-433f-b1d8-9fab79161c2c",
   "metadata": {},
   "source": [
    "## LATER \n",
    "Classification Objective Function\n",
    "We concatenate the sentence embeddings \n",
    " and \n",
    " with the element-wise difference \n",
    " and multiply the result with the trainable weight \n",
    ":\n",
    "\n",
    "\n",
    "where \n",
    " is the dimension of the sentence embeddings and k the number of labels. We optimize cross-entropy loss. This structure is depicted in Figure 1.\n",
    "\n",
    "Regression Objective Function.\n",
    "The cosine similarity between the two sentence embeddings \n",
    " and \n",
    " is computed. We use means quared-error loss as the objective function.\n",
    "\n",
    "(Manhatten / Euclidean distance, semantically similar sentences can be found.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6a881a9-f393-41ec-86d4-8bb32550e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurations(u,v):\n",
    "    # build the |u-v| tensor\n",
    "    uv = torch.sub(u, v)   # batch_size,hidden_dim\n",
    "    uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "    \n",
    "    # concatenate u, v, |u-v|\n",
    "    x = torch.cat([u, v, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "    return x\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    dot_product = np.dot(u, v)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    similarity = dot_product / (norm_u * norm_v)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22707fce-40ab-4883-9c28-1b9f4157ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_head = torch.nn.Linear(768*3, 3).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "optimizer_classifier = torch.optim.Adam(classifier_head.parameters(), lr=2e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9566e9d-0bfc-4050-ac3e-39f1a077b273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_562707/928846991.py:12: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  scheduler.step()\n",
      "/tmp/ipykernel_562707/928846991.py:20: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  scheduler_classifier.step()\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# and setup a warmup for the first ~10% steps\n",
    "total_steps = int(len(raw_dataset) / batch_size)\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler.step()\n",
    "\n",
    "scheduler_classifier = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer_classifier, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler_classifier.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8634fcfc-8951-417e-834d-96e7c988f6af",
   "metadata": {},
   "source": [
    "# 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcb7be-0fc2-4cc6-aba5-5ce3c5321776",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee71f1-047c-43dc-b412-8f950b0cbc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_epoch = 5\n",
    "# 1 epoch should be enough, increase if wanted\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    classifier_head.train()\n",
    "    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, leave=True)):\n",
    "        # zero all gradients on each new step\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_classifier.zero_grad()\n",
    "\n",
    "        # prepare batches and more all to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        segment_ids = torch.zeros(batch_size, max_seq_length, dtype=torch.int32).to(device)  # each input contains only one sentence hence we define them all as sentence '0'\n",
    "        label = batch['labels'].to(device)\n",
    "\n",
    "        # extract token embeddings from BERT at last_hidden_state\n",
    "        u_last_hidden_state = model.get_last_hidden_state(inputs_ids_a, segment_ids)\n",
    "        v_last_hidden_state = model.get_last_hidden_state(inputs_ids_b, segment_ids)\n",
    "\n",
    "        # get the mean pooled vectors\n",
    "        u_mean_pool = mean_pool(u_last_hidden_state, attention_a) # batch_size, hidden_dim\n",
    "        v_mean_pool = mean_pool(v_last_hidden_state, attention_b) # batch_size, hidden_dim\n",
    "\n",
    "        # build the |u-v| tensor\n",
    "        uv = torch.sub(u_mean_pool, v_mean_pool)   # batch_size,hidden_dim\n",
    "        uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "\n",
    "        # concatenate u, v, |u-v|\n",
    "        x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "\n",
    "        # process concatenated tensor through classifier_head\n",
    "        x = classifier_head(x) #batch_size, classifer\n",
    "\n",
    "        # calculate the 'softmax-loss' between predicted and true label\n",
    "        loss = criterion(x, label)\n",
    "\n",
    "        # using loss, calculate gradients and then optimizerize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_classifier.step()\n",
    "\n",
    "        scheduler.step() # update learning rate scheduler\n",
    "        scheduler_classifier.step()\n",
    "\n",
    "    print(f'Epoch: {epoch + 1} | loss = {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452efea-6654-4613-8f35-fa50def9c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "predictions = []\n",
    "probabilities = []\n",
    "classes = [\"entailment\", \"neutral\", \"contradiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37533397-08d3-41f1-a9db-8bfe2d4e5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "classifier_head.eval()\n",
    "total_similarity = 0\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        # Move batches to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        segment_ids = torch.zeros(inputs_ids_a.shape[0], inputs_ids_a.shape[1], dtype=torch.int32).to(device)\n",
    "        label = batch['labels'].to(device)\n",
    "\n",
    "        # Extract token embeddings from BERT\n",
    "        u = model.get_last_hidden_state(inputs_ids_a, segment_ids)  # (batch_size, seq_len, hidden_dim)\n",
    "        v = model.get_last_hidden_state(inputs_ids_b, segment_ids)  # (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        # Get the mean pooled vectors (Keep them as Tensors)\n",
    "        u_mean_pool = mean_pool(u, attention_a)  # (batch_size, hidden_dim)\n",
    "        v_mean_pool = mean_pool(v, attention_b)  # (batch_size, hidden_dim)\n",
    "\n",
    "        # Computing cosine similarity\n",
    "        similarity_score = cosine_similarity(u_mean_pool.cpu().numpy().reshape(-1), v_mean_pool.cpu().numpy().reshape(-1))\n",
    "        total_similarity += similarity_score\n",
    "\n",
    "        # Concatenate [u, v, |u - v|]\n",
    "        uv_abs = torch.abs(u_mean_pool - v_mean_pool)  # [batch_size, hidden_dim]\n",
    "        x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1)  # [batch_size, 3*hidden_dim]\n",
    "\n",
    "        # Classification\n",
    "        logit_fn = classifier_head(x)  # (batch_size, num_classes)\n",
    "        probs = torch.nn.functional.softmax(logit_fn, dim=-1)\n",
    "\n",
    "        preds = torch.argmax(logit_fn, dim=-1)\n",
    "\n",
    "        labels.extend(label.cpu().tolist())\n",
    "        probabilities.extend(probs.cpu().tolist())\n",
    "        predictions.extend(preds.cpu().tolist())\n",
    "\n",
    "average_similarity = total_similarity / len(eval_dataloader)\n",
    "print(f\"Average Cosine Similarity: {average_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c667f92-e57d-4103-9ac5-8dba90bb16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels, predictions, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac9591-998c-4b17-b6cb-77df03c56342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "torch.save([model.params, model.state_dict()], 'model/sen_bert.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096aa7db-01a5-4061-ae5c-9fe5619b40ec",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef1683-d510-452f-accb-84ba6e0e3d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(model, tokenizer, sentence_a, sentence_b, device):\n",
    "    # Tokenize and convert sentences to input IDs and attention masks\n",
    "    inputs_a = tokenizer(sentence_a, return_tensors='pt', max_length=max_seq_length, truncation=True, padding='max_length').to(device)\n",
    "    inputs_b = tokenizer(sentence_b, return_tensors='pt', max_length=max_seq_length, truncation=True, padding='max_length').to(device)\n",
    "\n",
    "    # Move input IDs and attention masks to the active device\n",
    "    inputs_ids_a = inputs_a['input_ids']\n",
    "    attention_a = inputs_a['attention_mask']\n",
    "    inputs_ids_b = inputs_b['input_ids']\n",
    "    attention_b = inputs_b['attention_mask']\n",
    "    segment_ids = torch.zeros(1, max_seq_length, dtype=torch.int32).to(device)\n",
    "\n",
    "    # Extract token embeddings from BERT\n",
    "    u = model.get_last_hidden_state(inputs_ids_a, segment_ids)  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "    v = model.get_last_hidden_state(inputs_ids_b, segment_ids)  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "    # Get the mean-pooled vectors\n",
    "    u = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
    "    v = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_score = cosine_similarity(u, v)\n",
    "\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c79757-8e4b-4ad0-80bb-de4fb850de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "sentence_a = 'Your contribution helped make it possible for us to provide our students with a quality education.'\n",
    "sentence_b = \"Your contributions were of no help with our students' education.\"\n",
    "similarity = calculate_similarity(model, tokenizer, sentence_a, sentence_b, device)\n",
    "print(f\"Cosine Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75c153-e126-4172-8258-693310995ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = 'An older man is drinking orange juice at a restaurant.'\n",
    "sentence_b = \"A man is drinking juice.\"\n",
    "similarity = calculate_similarity(model, tokenizer, sentence_a, sentence_b, device)\n",
    "print(f\"Cosine Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5c531a-4bb0-4e56-b66d-e2f5ed9c138c",
   "metadata": {},
   "source": [
    "# Task-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e57608-d091-42a3-95da-501f161d2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "pre_trained_model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb13b12d-6001-472a-b74a-aea6a1fdd0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78299428-31d8-43c4-b297-32c38b2bc3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sentence = [\"The cat is sleeping on the couch.\", \"The feline is resting on the sofa.\"]\n",
    "opp_sentence = [\"He is very punctual and reliable.\", \"You can never count on him to be on time.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39ecbf-a86f-4410-a48c-257b1824a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(pos_sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_output = pre_trained_model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5409100-e8f7-4740-876a-1ada57f92b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bSz5jzj61nHc"
   },
   "source": [
    "# BERT (Updated 1 Feb 2025, Available CUDA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8kZmr4ItGUj"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from   random import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Visible device count: 1\n",
      "Device 0 name: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Visible device count:\", torch.cuda.device_count())\n",
    "print(\"Device 0 name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data\n",
    "\n",
    "For simplicity, we shall use very simple data like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 100000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.en\",\n",
    "    split=\"train[:100000]\"\n",
    ")\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 100000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing unwanted columns\n",
    "dataset = dataset.remove_columns(['id', 'url', 'title'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Academy Award for Best Production Design recognizes achievement for art direction in film. The category's original name was Best Art Direction, but was changed to its current name in 2012 for the 85th Academy Awards. This change resulted from the Art Director's branch of the Academy of Motion Picture Arts and Sciences (AMPAS) being renamed the Designer's branch. Since 1947, the award is shared with the set decorator(s). It is awarded to the best interior design in a film.  The films below are listed with their production year (for example, the 2000 Academy Award for Best Art Direction is given to a film from 1999). In the lists below, the winner of the award for each year is shown first, followed by the other nominees in alphabetical order.  Superlatives  Winners and nominees  1920s  1930s  1940s  1950s  1960s  1970s  1980s  1990s  2000s  2010s  2020s  See also  BAFTA Award for Best Production Design  Critics' Choice Movie Award for Best Production Design  Notes  References  Best Production Design  Awards for best art direction\",\n",
       " 'Actresses (Catalan: Actrius) is a 1997 Catalan language Spanish drama film produced and directed by Ventura Pons and based on the award-winning stage play E.R. by Josep Maria Benet i Jornet. The film has no male actors, with all roles played by females. The film was produced in 1996.  Synopsis In order to prepare herself to play a role commemorating the life of legendary actress Empar Ribera, young actress (Mercè Pons) interviews three established actresses who had been the Ribera\\'s pupils: the international diva Glòria Marc (Núria Espert), the television star Assumpta Roca (Rosa Maria Sardà), and dubbing director Maria Caminal (Anna Lizaran).  Cast  Núria Espert as Glòria Marc  Rosa Maria Sardà as Assumpta Roca  Anna Lizaran as Maria Caminal  Mercè Pons as Estudiant  Recognition  Screenings Actrius screened in 2001 at the Grauman\\'s Egyptian Theatre in an American Cinematheque retrospective of the works of its director. The film had first screened at the same location in 1998. It was also shown at the 1997 Stockholm International Film Festival.  Reception In Movie - Film - Review, Christopher Tookey wrote that though the actresses were \"competent in roles that may have some reference to their own careers\", the film \"is visually unimaginative, never escapes its stage origins, and is almost totally lacking in revelation or surprising incident\". Noting that there were \"occasional, refreshing moments of intergenerational bitchiness\", they did not \"justify comparisons to All About Eve\", and were \"insufficiently different to deserve critical parallels with Rashomon\". He also wrote that The Guardian called the film a \"slow, stuffy chamber-piece\", and that The Evening Standard stated the film\\'s \"best moments exhibit the bitchy tantrums seething beneath the threesome\\'s composed veneers\". MRQE wrote \"This cinematic adaptation of a theatrical work is true to the original, but does not stray far from a theatrical rendering of the story.\"  Awards and nominations  1997, won \\'Best Catalan Film\\' at Butaca Awards for Ventura Pons  1997, won \\'Best Catalan Film Actress\\' at Butaca Awards, shared by Núria Espert, Rosa Maria Sardà, Anna Lizaran, and Mercè Pons  1998, nominated for \\'Best Screenplay\\' at Goya Awards, shared by Josep Maria Benet i Jornet and Ventura Pons  References  External links     as archived 17 February 2009 (Spanish)  1997 films 1997 drama films Spanish films Catalan-language films Films set in Barcelona Films directed by Ventura Pons Spanish drama films']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = dataset['text']\n",
    "sentences = [x.replace(\"\\n\", \" \") for x in sentences]\n",
    "sentences = [x for x in sentences if len(x.split()) <= 500]\n",
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"the academy award for best production design recognizes achievement for art direction in film the category's original name was best art direction but was changed to its current name in 2012 for the 85th academy awards this change resulted from the art director's branch of the academy of motion picture arts and sciences (ampas) being renamed the designer's branch since 1947 the award is shared with the set decorator(s) it is awarded to the best interior design in a film  the films below are listed with their production year (for example the 2000 academy award for best art direction is given to a film from 1999) in the lists below the winner of the award for each year is shown first followed by the other nominees in alphabetical order  superlatives  winners and nominees  1920s  1930s  1940s  1950s  1960s  1970s  1980s  1990s  2000s  2010s  2020s  see also  bafta award for best production design  critics' choice movie award for best production design  notes  references  best production design  awards for best art direction\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [x.lower() for x in sentences] #lower case\n",
    "text = [re.sub(\"[.,!?\\\\-]\", '', x) for x in text] #clean all symbols\n",
    "text[:1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making vocabs\n",
    "\n",
    "Before making the vocabs, let's remove all question marks and perios, etc, then turn everything to lowercase, and then simply split the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27fdf9233904169bac575002e6e14e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating word2id: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "323367"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Combine everything into one to make vocab\n",
    "word_list = list(set(\" \".join(text).split()))\n",
    "word2id = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3}  # special tokens\n",
    "\n",
    "# Create the word2id in a single pass\n",
    "for i, w in tqdm(enumerate(word_list), desc=\"Creating word2id\"):\n",
    "    word2id[w] = i + 4  # because 0-3 are already occupied\n",
    "\n",
    "# Precompute the id2word mapping (this can be done once after word2id is fully populated)\n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "vocab_size = len(word2id)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb9b68e27a34ec09270555c2e66b406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing sentences:   0%|          | 0/27773 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of all tokens for the whole text\n",
    "token_list = []\n",
    "\n",
    "# Process sentences more efficiently\n",
    "for sentence in tqdm(text, desc=\"Processing sentences\"):\n",
    "    token_list.append([word2id[word] for word in sentence.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323367"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Academy Award for Best Production Design recognizes achievement for art direction in film. The category's original name was Best Art Direction, but was changed to its current name in 2012 for the 85th Academy Awards. This change resulted from the Art Director's branch of the Academy of Motion Picture Arts and Sciences (AMPAS) being renamed the Designer's branch. Since 1947, the award is shared with the set decorator(s). It is awarded to the best interior design in a film.  The films below are listed with their production year (for example, the 2000 Academy Award for Best Art Direction is given to a film from 1999). In the lists below, the winner of the award for each year is shown first, followed by the other nominees in alphabetical order.  Superlatives  Winners and nominees  1920s  1930s  1940s  1950s  1960s  1970s  1980s  1990s  2000s  2010s  2020s  See also  BAFTA Award for Best Production Design  Critics' Choice Movie Award for Best Production Design  Notes  References  Best Production Design  Awards for best art direction\",\n",
       " 'Actresses (Catalan: Actrius) is a 1997 Catalan language Spanish drama film produced and directed by Ventura Pons and based on the award-winning stage play E.R. by Josep Maria Benet i Jornet. The film has no male actors, with all roles played by females. The film was produced in 1996.  Synopsis In order to prepare herself to play a role commemorating the life of legendary actress Empar Ribera, young actress (Mercè Pons) interviews three established actresses who had been the Ribera\\'s pupils: the international diva Glòria Marc (Núria Espert), the television star Assumpta Roca (Rosa Maria Sardà), and dubbing director Maria Caminal (Anna Lizaran).  Cast  Núria Espert as Glòria Marc  Rosa Maria Sardà as Assumpta Roca  Anna Lizaran as Maria Caminal  Mercè Pons as Estudiant  Recognition  Screenings Actrius screened in 2001 at the Grauman\\'s Egyptian Theatre in an American Cinematheque retrospective of the works of its director. The film had first screened at the same location in 1998. It was also shown at the 1997 Stockholm International Film Festival.  Reception In Movie - Film - Review, Christopher Tookey wrote that though the actresses were \"competent in roles that may have some reference to their own careers\", the film \"is visually unimaginative, never escapes its stage origins, and is almost totally lacking in revelation or surprising incident\". Noting that there were \"occasional, refreshing moments of intergenerational bitchiness\", they did not \"justify comparisons to All About Eve\", and were \"insufficiently different to deserve critical parallels with Rashomon\". He also wrote that The Guardian called the film a \"slow, stuffy chamber-piece\", and that The Evening Standard stated the film\\'s \"best moments exhibit the bitchy tantrums seething beneath the threesome\\'s composed veneers\". MRQE wrote \"This cinematic adaptation of a theatrical work is true to the original, but does not stray far from a theatrical rendering of the story.\"  Awards and nominations  1997, won \\'Best Catalan Film\\' at Butaca Awards for Ventura Pons  1997, won \\'Best Catalan Film Actress\\' at Butaca Awards, shared by Núria Espert, Rosa Maria Sardà, Anna Lizaran, and Mercè Pons  1998, nominated for \\'Best Screenplay\\' at Goya Awards, shared by Josep Maria Benet i Jornet and Ventura Pons  References  External links     as archived 17 February 2009 (Spanish)  1997 films 1997 drama films Spanish films Catalan-language films Films set in Barcelona Films directed by Ventura Pons Spanish drama films']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at sentences\n",
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZ42SFLKtsv_",
    "outputId": "16c28ac8-8349-48ab-f1d3-a9431e658349",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[153988,\n",
       "  110810,\n",
       "  59780,\n",
       "  123729,\n",
       "  31982,\n",
       "  103915,\n",
       "  150829,\n",
       "  15691,\n",
       "  5729,\n",
       "  123729,\n",
       "  67917,\n",
       "  241634,\n",
       "  243487,\n",
       "  90392,\n",
       "  153988,\n",
       "  309380,\n",
       "  236575,\n",
       "  237311,\n",
       "  146633,\n",
       "  31982,\n",
       "  67917,\n",
       "  241634,\n",
       "  237885,\n",
       "  146633,\n",
       "  167084,\n",
       "  126472,\n",
       "  33581,\n",
       "  192356,\n",
       "  237311,\n",
       "  243487,\n",
       "  176880,\n",
       "  123729,\n",
       "  153988,\n",
       "  266440,\n",
       "  110810,\n",
       "  211190,\n",
       "  175199,\n",
       "  208446,\n",
       "  188702,\n",
       "  283853,\n",
       "  153988,\n",
       "  67917,\n",
       "  190942,\n",
       "  237419,\n",
       "  254205,\n",
       "  153988,\n",
       "  110810,\n",
       "  254205,\n",
       "  25033,\n",
       "  277563,\n",
       "  179791,\n",
       "  150880,\n",
       "  185606,\n",
       "  306523,\n",
       "  215477,\n",
       "  123178,\n",
       "  153988,\n",
       "  31704,\n",
       "  237419,\n",
       "  269890,\n",
       "  105166,\n",
       "  153988,\n",
       "  59780,\n",
       "  119892,\n",
       "  279792,\n",
       "  78155,\n",
       "  153988,\n",
       "  79880,\n",
       "  151937,\n",
       "  269442,\n",
       "  119892,\n",
       "  16994,\n",
       "  126472,\n",
       "  153988,\n",
       "  31982,\n",
       "  287657,\n",
       "  150829,\n",
       "  243487,\n",
       "  75545,\n",
       "  90392,\n",
       "  153988,\n",
       "  174318,\n",
       "  135473,\n",
       "  85012,\n",
       "  305449,\n",
       "  78155,\n",
       "  156953,\n",
       "  103915,\n",
       "  195114,\n",
       "  76584,\n",
       "  282906,\n",
       "  153988,\n",
       "  196290,\n",
       "  110810,\n",
       "  59780,\n",
       "  123729,\n",
       "  31982,\n",
       "  67917,\n",
       "  241634,\n",
       "  119892,\n",
       "  183324,\n",
       "  126472,\n",
       "  75545,\n",
       "  90392,\n",
       "  283853,\n",
       "  31594,\n",
       "  243487,\n",
       "  153988,\n",
       "  136955,\n",
       "  135473,\n",
       "  153988,\n",
       "  293979,\n",
       "  254205,\n",
       "  153988,\n",
       "  59780,\n",
       "  123729,\n",
       "  95940,\n",
       "  195114,\n",
       "  119892,\n",
       "  131236,\n",
       "  36675,\n",
       "  209130,\n",
       "  256205,\n",
       "  153988,\n",
       "  83692,\n",
       "  296534,\n",
       "  243487,\n",
       "  144809,\n",
       "  166926,\n",
       "  120032,\n",
       "  172939,\n",
       "  150880,\n",
       "  296534,\n",
       "  164035,\n",
       "  124200,\n",
       "  98519,\n",
       "  271232,\n",
       "  6442,\n",
       "  53558,\n",
       "  127582,\n",
       "  206190,\n",
       "  271846,\n",
       "  62314,\n",
       "  312651,\n",
       "  193463,\n",
       "  253087,\n",
       "  113857,\n",
       "  59780,\n",
       "  123729,\n",
       "  31982,\n",
       "  103915,\n",
       "  150829,\n",
       "  90015,\n",
       "  86345,\n",
       "  147914,\n",
       "  59780,\n",
       "  123729,\n",
       "  31982,\n",
       "  103915,\n",
       "  150829,\n",
       "  213559,\n",
       "  217157,\n",
       "  31982,\n",
       "  103915,\n",
       "  150829,\n",
       "  211190,\n",
       "  123729,\n",
       "  31982,\n",
       "  67917,\n",
       "  241634],\n",
       " [88947,\n",
       "  207259,\n",
       "  319911,\n",
       "  119892,\n",
       "  75545,\n",
       "  249566,\n",
       "  309384,\n",
       "  73738,\n",
       "  159334,\n",
       "  137459,\n",
       "  90392,\n",
       "  12245,\n",
       "  150880,\n",
       "  162169,\n",
       "  256205,\n",
       "  236040,\n",
       "  4776,\n",
       "  150880,\n",
       "  138500,\n",
       "  269868,\n",
       "  153988,\n",
       "  164907,\n",
       "  211207,\n",
       "  96431,\n",
       "  210593,\n",
       "  256205,\n",
       "  215285,\n",
       "  85621,\n",
       "  184994,\n",
       "  122349,\n",
       "  261585,\n",
       "  153988,\n",
       "  90392,\n",
       "  98060,\n",
       "  12267,\n",
       "  274702,\n",
       "  188956,\n",
       "  78155,\n",
       "  157110,\n",
       "  249706,\n",
       "  49249,\n",
       "  256205,\n",
       "  4136,\n",
       "  153988,\n",
       "  90392,\n",
       "  146633,\n",
       "  12245,\n",
       "  243487,\n",
       "  210831,\n",
       "  296714,\n",
       "  243487,\n",
       "  166926,\n",
       "  126472,\n",
       "  269049,\n",
       "  57293,\n",
       "  126472,\n",
       "  96431,\n",
       "  75545,\n",
       "  145356,\n",
       "  11590,\n",
       "  153988,\n",
       "  26699,\n",
       "  254205,\n",
       "  245372,\n",
       "  147803,\n",
       "  145272,\n",
       "  135529,\n",
       "  136178,\n",
       "  147803,\n",
       "  81646,\n",
       "  174679,\n",
       "  302946,\n",
       "  232363,\n",
       "  166655,\n",
       "  88947,\n",
       "  155008,\n",
       "  294061,\n",
       "  65690,\n",
       "  153988,\n",
       "  134444,\n",
       "  30787,\n",
       "  153988,\n",
       "  61595,\n",
       "  239038,\n",
       "  195589,\n",
       "  255647,\n",
       "  271626,\n",
       "  266333,\n",
       "  153988,\n",
       "  76050,\n",
       "  3610,\n",
       "  107343,\n",
       "  303902,\n",
       "  227564,\n",
       "  85621,\n",
       "  104950,\n",
       "  150880,\n",
       "  228020,\n",
       "  161183,\n",
       "  85621,\n",
       "  247636,\n",
       "  174912,\n",
       "  134090,\n",
       "  76232,\n",
       "  160790,\n",
       "  317027,\n",
       "  60190,\n",
       "  195589,\n",
       "  255647,\n",
       "  274975,\n",
       "  85621,\n",
       "  109230,\n",
       "  60190,\n",
       "  107343,\n",
       "  303902,\n",
       "  36005,\n",
       "  98513,\n",
       "  60190,\n",
       "  85621,\n",
       "  247636,\n",
       "  267394,\n",
       "  4776,\n",
       "  60190,\n",
       "  263602,\n",
       "  291034,\n",
       "  232939,\n",
       "  258508,\n",
       "  241897,\n",
       "  243487,\n",
       "  127161,\n",
       "  194408,\n",
       "  153988,\n",
       "  271356,\n",
       "  301725,\n",
       "  228317,\n",
       "  243487,\n",
       "  49302,\n",
       "  145422,\n",
       "  93811,\n",
       "  19287,\n",
       "  254205,\n",
       "  153988,\n",
       "  153626,\n",
       "  254205,\n",
       "  33581,\n",
       "  161183,\n",
       "  153988,\n",
       "  90392,\n",
       "  294061,\n",
       "  36675,\n",
       "  241897,\n",
       "  194408,\n",
       "  153988,\n",
       "  130835,\n",
       "  246757,\n",
       "  243487,\n",
       "  41160,\n",
       "  269442,\n",
       "  146633,\n",
       "  253087,\n",
       "  131236,\n",
       "  194408,\n",
       "  153988,\n",
       "  249566,\n",
       "  10474,\n",
       "  61595,\n",
       "  90392,\n",
       "  85838,\n",
       "  196077,\n",
       "  243487,\n",
       "  147914,\n",
       "  90392,\n",
       "  244088,\n",
       "  258527,\n",
       "  248157,\n",
       "  99718,\n",
       "  165433,\n",
       "  67525,\n",
       "  153988,\n",
       "  88947,\n",
       "  170900,\n",
       "  124464,\n",
       "  243487,\n",
       "  249706,\n",
       "  165433,\n",
       "  301799,\n",
       "  239455,\n",
       "  70905,\n",
       "  23492,\n",
       "  126472,\n",
       "  156953,\n",
       "  77933,\n",
       "  52417,\n",
       "  153988,\n",
       "  90392,\n",
       "  81848,\n",
       "  64737,\n",
       "  122136,\n",
       "  142633,\n",
       "  264308,\n",
       "  33581,\n",
       "  211207,\n",
       "  320959,\n",
       "  150880,\n",
       "  119892,\n",
       "  293138,\n",
       "  112654,\n",
       "  123927,\n",
       "  243487,\n",
       "  146367,\n",
       "  231334,\n",
       "  284016,\n",
       "  198673,\n",
       "  231378,\n",
       "  165433,\n",
       "  24729,\n",
       "  170900,\n",
       "  160138,\n",
       "  259225,\n",
       "  218911,\n",
       "  254205,\n",
       "  64027,\n",
       "  317658,\n",
       "  120928,\n",
       "  173685,\n",
       "  308787,\n",
       "  136827,\n",
       "  270141,\n",
       "  126472,\n",
       "  157110,\n",
       "  257286,\n",
       "  282219,\n",
       "  150880,\n",
       "  170900,\n",
       "  14305,\n",
       "  186622,\n",
       "  126472,\n",
       "  203275,\n",
       "  174297,\n",
       "  112163,\n",
       "  78155,\n",
       "  198590,\n",
       "  116964,\n",
       "  253087,\n",
       "  99718,\n",
       "  165433,\n",
       "  153988,\n",
       "  64505,\n",
       "  175054,\n",
       "  153988,\n",
       "  90392,\n",
       "  75545,\n",
       "  115845,\n",
       "  38470,\n",
       "  13972,\n",
       "  150880,\n",
       "  165433,\n",
       "  153988,\n",
       "  187422,\n",
       "  87221,\n",
       "  55115,\n",
       "  153988,\n",
       "  74070,\n",
       "  207349,\n",
       "  218911,\n",
       "  171465,\n",
       "  153988,\n",
       "  120454,\n",
       "  45185,\n",
       "  322083,\n",
       "  14099,\n",
       "  153988,\n",
       "  310041,\n",
       "  294863,\n",
       "  80099,\n",
       "  134286,\n",
       "  99718,\n",
       "  99401,\n",
       "  300776,\n",
       "  11407,\n",
       "  254205,\n",
       "  75545,\n",
       "  271953,\n",
       "  259188,\n",
       "  119892,\n",
       "  9672,\n",
       "  126472,\n",
       "  153988,\n",
       "  236575,\n",
       "  237885,\n",
       "  254585,\n",
       "  308787,\n",
       "  315554,\n",
       "  112782,\n",
       "  283853,\n",
       "  75545,\n",
       "  271953,\n",
       "  284574,\n",
       "  254205,\n",
       "  153988,\n",
       "  7666,\n",
       "  211190,\n",
       "  150880,\n",
       "  236825,\n",
       "  249566,\n",
       "  27969,\n",
       "  54265,\n",
       "  309384,\n",
       "  211909,\n",
       "  194408,\n",
       "  148707,\n",
       "  211190,\n",
       "  123729,\n",
       "  236040,\n",
       "  4776,\n",
       "  249566,\n",
       "  27969,\n",
       "  54265,\n",
       "  309384,\n",
       "  90392,\n",
       "  304581,\n",
       "  194408,\n",
       "  148707,\n",
       "  211190,\n",
       "  279792,\n",
       "  256205,\n",
       "  160790,\n",
       "  317027,\n",
       "  274975,\n",
       "  85621,\n",
       "  109230,\n",
       "  36005,\n",
       "  98513,\n",
       "  150880,\n",
       "  267394,\n",
       "  4776,\n",
       "  41160,\n",
       "  82636,\n",
       "  123729,\n",
       "  54265,\n",
       "  208992,\n",
       "  194408,\n",
       "  310582,\n",
       "  211190,\n",
       "  279792,\n",
       "  256205,\n",
       "  215285,\n",
       "  85621,\n",
       "  184994,\n",
       "  122349,\n",
       "  261585,\n",
       "  150880,\n",
       "  236040,\n",
       "  4776,\n",
       "  217157,\n",
       "  108656,\n",
       "  238979,\n",
       "  60190,\n",
       "  63009,\n",
       "  264385,\n",
       "  125517,\n",
       "  90288,\n",
       "  301396,\n",
       "  249566,\n",
       "  174318,\n",
       "  249566,\n",
       "  137459,\n",
       "  174318,\n",
       "  159334,\n",
       "  174318,\n",
       "  109247,\n",
       "  174318,\n",
       "  174318,\n",
       "  79880,\n",
       "  243487,\n",
       "  130858,\n",
       "  174318,\n",
       "  162169,\n",
       "  256205,\n",
       "  236040,\n",
       "  4776,\n",
       "  159334,\n",
       "  137459,\n",
       "  174318]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at token_list\n",
    "token_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "academy\n",
      "award\n",
      "for\n",
      "best\n",
      "production\n",
      "design\n",
      "recognizes\n",
      "achievement\n",
      "for\n",
      "art\n",
      "direction\n",
      "in\n",
      "film\n",
      "the\n",
      "category's\n",
      "original\n",
      "name\n",
      "was\n",
      "best\n",
      "art\n",
      "direction\n",
      "but\n",
      "was\n",
      "changed\n",
      "to\n",
      "its\n",
      "current\n",
      "name\n",
      "in\n",
      "2012\n",
      "for\n",
      "the\n",
      "85th\n",
      "academy\n",
      "awards\n",
      "this\n",
      "change\n",
      "resulted\n",
      "from\n",
      "the\n",
      "art\n",
      "director's\n",
      "branch\n",
      "of\n",
      "the\n",
      "academy\n",
      "of\n",
      "motion\n",
      "picture\n",
      "arts\n",
      "and\n",
      "sciences\n",
      "(ampas)\n",
      "being\n",
      "renamed\n",
      "the\n",
      "designer's\n",
      "branch\n",
      "since\n",
      "1947\n",
      "the\n",
      "award\n",
      "is\n",
      "shared\n",
      "with\n",
      "the\n",
      "set\n",
      "decorator(s)\n",
      "it\n",
      "is\n",
      "awarded\n",
      "to\n",
      "the\n",
      "best\n",
      "interior\n",
      "design\n",
      "in\n",
      "a\n",
      "film\n",
      "the\n",
      "films\n",
      "below\n",
      "are\n",
      "listed\n",
      "with\n",
      "their\n",
      "production\n",
      "year\n",
      "(for\n",
      "example\n",
      "the\n",
      "2000\n",
      "academy\n",
      "award\n",
      "for\n",
      "best\n",
      "art\n",
      "direction\n",
      "is\n",
      "given\n",
      "to\n",
      "a\n",
      "film\n",
      "from\n",
      "1999)\n",
      "in\n",
      "the\n",
      "lists\n",
      "below\n",
      "the\n",
      "winner\n",
      "of\n",
      "the\n",
      "award\n",
      "for\n",
      "each\n",
      "year\n",
      "is\n",
      "shown\n",
      "first\n",
      "followed\n",
      "by\n",
      "the\n",
      "other\n",
      "nominees\n",
      "in\n",
      "alphabetical\n",
      "order\n",
      "superlatives\n",
      "winners\n",
      "and\n",
      "nominees\n",
      "1920s\n",
      "1930s\n",
      "1940s\n",
      "1950s\n",
      "1960s\n",
      "1970s\n",
      "1980s\n",
      "1990s\n",
      "2000s\n",
      "2010s\n",
      "2020s\n",
      "see\n",
      "also\n",
      "bafta\n",
      "award\n",
      "for\n",
      "best\n",
      "production\n",
      "design\n",
      "critics'\n",
      "choice\n",
      "movie\n",
      "award\n",
      "for\n",
      "best\n",
      "production\n",
      "design\n",
      "notes\n",
      "references\n",
      "best\n",
      "production\n",
      "design\n",
      "awards\n",
      "for\n",
      "best\n",
      "art\n",
      "direction\n"
     ]
    }
   ],
   "source": [
    "#testing one sentence\n",
    "for tokens in token_list[0]:\n",
    "    print(id2word[tokens])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data loader\n",
    "\n",
    "We gonna make dataloader.  Inside here, we need to make two types of embeddings: **token embedding** and **segment embedding**\n",
    "\n",
    "1. **Token embedding** - Given “The cat is walking. The dog is barking”, we add [CLS] and [SEP] >> “[CLS] the cat is walking [SEP] the dog is barking”. \n",
    "\n",
    "2. **Segment embedding**\n",
    "A segment embedding separates two sentences, i.e., [0 0 0 0 1 1 1 1 ]\n",
    "\n",
    "3. **Masking**\n",
    "As mentioned in the original paper, BERT randomly assigns masks to 15% of the sequence. In this 15%, 80% is replaced with masks, while 10% is replaced with random tokens, and the rest 10% is left as is.  Here we specified `max_pred` \n",
    "\n",
    "4. **Padding**\n",
    "Once we mask, we will add padding. For simplicity, here we padded until some specified `max_len`. \n",
    "\n",
    "Note:  `positive` and `negative` are just simply counts to keep track of the batch size.  `positive` refers to two sentences that are really next to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "max_mask   = 5  # max masked tokens when 15% exceed, it will only be max_pred\n",
    "max_len    = 1000 # maximum of length to be padded; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TtyOOmRntu8w"
   },
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "    batch = []\n",
    "    half_batch_size = batch_size // 2\n",
    "    positive = negative = 0\n",
    "    while positive != half_batch_size or negative != half_batch_size:\n",
    "\n",
    "        #randomly choose two sentence\n",
    "        tokens_a_index, tokens_b_index = np.random.randint(len(sentences), size=2)\n",
    "        tokens_a, tokens_b            = token_list[tokens_a_index], token_list[tokens_b_index]\n",
    "\n",
    "        #1. token embedding - add CLS and SEP\n",
    "        input_ids = [word2id['[CLS]']] + tokens_a + [word2id['[SEP]']] + tokens_b + [word2id['[SEP]']]\n",
    "\n",
    "        #2. segment embedding - which sentence is 0 and 1\n",
    "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        n_pred = min(max_mask, max(1, int(round(len(input_ids) * 0.15))))\n",
    "        #get all the pos excluding CLS and SEP\n",
    "        candidates_masked_pos = [i for i, token in enumerate(input_ids) if token != word2id['[CLS]']\n",
    "                                 and token != word2id['[SEP]']]\n",
    "        np.random.shuffle(candidates_masked_pos)\n",
    "        masked_tokens, masked_pos = [], []\n",
    "        #simply loop and mask accordingly\n",
    "        for pos in candidates_masked_pos[:n_pred]:\n",
    "            masked_pos.append(pos)\n",
    "            masked_tokens.append(input_ids[pos])\n",
    "            rand_val = np.random.random()\n",
    "            if rand_val < 0.1:  #10% replace with random token\n",
    "                index = np.random.randint(4, vocab_size - 1)  # random token should not involve [PAD], [CLS], [SEP], [MASK]\n",
    "                input_ids[pos] = word2id[id2word[index]]\n",
    "            elif rand_val < 0.8:  #80 replace with [MASK]\n",
    "                input_ids[pos] = word2id['[MASK]']\n",
    "            else:\n",
    "                pass\n",
    "        if len(input_ids) > max_len:\n",
    "            input_ids = input_ids[:max_len]\n",
    "            segment_ids = segment_ids[:max_len]\n",
    "\n",
    "        #4. pad the sentence to the max length\n",
    "        n_pad = max_len - len(input_ids)\n",
    "        input_ids.extend([0] * n_pad)\n",
    "        segment_ids.extend([0] * n_pad)\n",
    "\n",
    "        #5. pad the mask tokens to the max length\n",
    "        if max_mask > n_pred:\n",
    "            n_pad = max_mask - n_pred\n",
    "            masked_tokens.extend([0] * n_pad)\n",
    "            masked_pos.extend([0] * n_pad)\n",
    "\n",
    "        #6. check whether is positive or negative\n",
    "        if tokens_a_index + 1 == tokens_b_index and positive < half_batch_size:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True])\n",
    "            positive += 1\n",
    "        elif tokens_a_index + 1 != tokens_b_index and negative < half_batch_size:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False])\n",
    "            negative += 1\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Q7_HC-Y0jC3K"
   },
   "outputs": [],
   "source": [
    "batch = make_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len of batch\n",
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1000]),\n",
       " torch.Size([2, 1000]),\n",
       " torch.Size([2, 5]),\n",
       " torch.Size([2, 5]),\n",
       " torch.Size([2]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape, segment_ids.shape, masked_tokens.shape, masked_pos.shape, isNext.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model\n",
    "\n",
    "Recall that BERT only uses the encoder.\n",
    "\n",
    "BERT has the following components:\n",
    "\n",
    "- Embedding layers\n",
    "- Attention Mask\n",
    "- Encoder layer\n",
    "- Multi-head attention\n",
    "- Scaled dot product attention\n",
    "- Position-wise feed-forward network\n",
    "- BERT (assembling all the components)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Embedding\n",
    "\n",
    "Here we simply generate the positional embedding, and sum the token embedding, positional embedding, and segment embedding together.\n",
    "\n",
    "<img src = \"figures/BERT_embed.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, n_segments, d_model, device):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)      # position embedding\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)  # segment(token type) embedding\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        #x, seg: (bs, len)\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long).to(self.device)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)  # (len,) -> (bs, len)\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "s1PGksqBNuZM"
   },
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k, device):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1).to(device)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(get_attn_pad_mask(input_ids, input_ids, device).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Encoder\n",
    "\n",
    "The encoder has two main components: \n",
    "\n",
    "- Multi-head Attention\n",
    "- Position-wise feed-forward network\n",
    "\n",
    "First let's make the wrapper called `EncoderLayer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, d_ff, d_k, device):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(n_heads, d_model, d_k, device)\n",
    "        self.pos_ffn       = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the scaled dot attention, to be used inside the multihead attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k, device):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([d_k])).to(device)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / self.scale # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the parameters first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 6    # number of Encoder of Encoder Layer\n",
    "n_heads  = 8    # number of heads in Multi-Head Attention\n",
    "d_model  = 768  # Embedding Size\n",
    "d_ff = 768 * 4  # 4*d_model, FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_segments = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the Multiheadattention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, d_k, device):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_k\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, self.d_v * n_heads)\n",
    "        self.device = device\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
    "\n",
    "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        context, attn = ScaledDotProductAttention(self.d_k, self.device)(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
    "        output = nn.Linear(self.n_heads * self.d_v, self.d_model, device=self.device)(context)\n",
    "        return nn.LayerNorm(self.d_model, device=self.device)(output + residual), attn # output: [batch_size x len_q x d_model]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the PoswiseFeedForwardNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch_size, len_seq, d_model) -> (batch_size, len_seq, d_ff) -> (batch_size, len_seq, d_model)\n",
    "        return self.fc2(F.gelu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Putting them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "OZ0TJ84W4SZw"
   },
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, n_layers, n_heads, d_model, d_ff, d_k, n_segments, vocab_size, max_len, device):\n",
    "        super(BERT, self).__init__()\n",
    "        self.params = {'n_layers': n_layers, 'n_heads': n_heads, 'd_model': d_model,\n",
    "                       'd_ff': d_ff, 'd_k': d_k, 'n_segments': n_segments,\n",
    "                       'vocab_size': vocab_size, 'max_len': max_len}\n",
    "        self.embedding = Embedding(vocab_size, max_len, n_segments, d_model, device)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(n_heads, d_model, d_ff, d_k, device) for _ in range(n_layers)])\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.activ = nn.Tanh()\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Linear(d_model, 2)\n",
    "        # decoder is shared with embedding layer\n",
    "        embed_weight = self.embedding.tok_embed.weight\n",
    "        n_vocab, n_dim = embed_weight.size()\n",
    "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
    "        self.decoder.weight = embed_weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input_ids, segment_ids, masked_pos):\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device)\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "        # output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\n",
    "        \n",
    "        # 1. predict next sentence\n",
    "        # it will be decided by first token(CLS)\n",
    "        h_pooled   = self.activ(self.fc(output[:, 0])) # [batch_size, d_model]\n",
    "        logits_nsp = self.classifier(h_pooled) # [batch_size, 2]\n",
    "\n",
    "        # 2. predict the masked token\n",
    "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1)) # [batch_size, max_pred, d_model]\n",
    "        h_masked = torch.gather(output, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n",
    "        h_masked  = self.norm(F.gelu(self.linear(h_masked)))\n",
    "        logits_lm = self.decoder(h_masked) + self.decoder_bias # [batch_size, max_pred, n_vocab]\n",
    "\n",
    "        return logits_lm, logits_nsp\n",
    "    \n",
    "    def get_last_hidden_state(self, input_ids, segment_ids):\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device)\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "n_layers = 12    # number of Encoder of Encoder Layer\n",
    "n_heads  = 12    # number of heads in Multi-Head Attention\n",
    "d_model  = 768  # Embedding Size\n",
    "d_ff = d_model * 4  # 4*d_model, FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_segments = 2\n",
    "\n",
    "num_epoch = 1000\n",
    "model = BERT(\n",
    "    n_layers, \n",
    "    n_heads, \n",
    "    d_model, \n",
    "    d_ff, \n",
    "    d_k, \n",
    "    n_segments, \n",
    "    vocab_size, \n",
    "    max_len, \n",
    "    device\n",
    ").to(device)  # Move model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UAG3SEP4UbU",
    "outputId": "bc6f202f-df37-4fac-843c-fb86bdb777b2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3770843354a24c5899ad69e4ca18ea5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 loss = 148.190948\n",
      "Epoch: 100 loss = 3.740366\n",
      "Epoch: 200 loss = 3.110257\n",
      "Epoch: 300 loss = 3.102159\n",
      "Epoch: 400 loss = 4.858214\n",
      "Epoch: 500 loss = 5.021757\n",
      "Epoch: 600 loss = 4.326852\n",
      "Epoch: 700 loss = 3.427927\n",
      "Epoch: 800 loss = 2.988678\n",
      "Epoch: 900 loss = 3.109298\n"
     ]
    }
   ],
   "source": [
    "batch = make_batch()\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
    "\n",
    "# Move inputs to GPU\n",
    "input_ids = input_ids.to(device)\n",
    "segment_ids = segment_ids.to(device)\n",
    "masked_tokens = masked_tokens.to(device)\n",
    "masked_pos = masked_pos.to(device)\n",
    "isNext = isNext.to(device)\n",
    "\n",
    "# Wrap the epoch loop with tqdm\n",
    "for epoch in tqdm(range(num_epoch), desc=\"Training Epochs\"):\n",
    "    optimizer.zero_grad()\n",
    "    logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)    \n",
    "    #logits_lm: (bs, max_mask, vocab_size) ==> (6, 5, 34)\n",
    "    #logits_nsp: (bs, yes/no) ==> (6, 2)\n",
    "\n",
    "    #1. mlm loss\n",
    "    #logits_lm.transpose: (bs, vocab_size, max_mask) vs. masked_tokens: (bs, max_mask)\n",
    "    loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens) # for masked LM\n",
    "    loss_lm = (loss_lm.float()).mean()\n",
    "    #2. nsp loss\n",
    "    #logits_nsp: (bs, 2) vs. isNext: (bs, )\n",
    "    loss_nsp = criterion(logits_nsp, isNext) # for sentence classification\n",
    "    \n",
    "    #3. combine loss\n",
    "    loss = loss_lm + loss_nsp\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch:', '%02d' % (epoch), 'loss =', '{:.6f}'.format(loss))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 323367\n",
      "masked_tokens min/max: 18289 307395\n",
      "input_ids max: 323065\n"
     ]
    }
   ],
   "source": [
    "batch = make_batch()\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
    "\n",
    "print(\"vocab_size:\", vocab_size)\n",
    "print(\"masked_tokens min/max:\", masked_tokens.min().item(), masked_tokens.max().item())\n",
    "print(\"input_ids max:\", input_ids.max().item())\n",
    "\n",
    "assert masked_tokens.min().item() >= 0\n",
    "assert masked_tokens.max().item() < vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_bert.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model after training\n",
    "torch.save([model.params, model.state_dict()], 'model/model_bert.pth')\n",
    "print(\"Model saved to model_bert.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference\n",
    "\n",
    "Since our dataset is very small, it won't work very well, but just for the sake of demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model and all its hyperparameters\n",
    "params, state = torch.load('model/model_bert.pth')\n",
    "model_bert = BERT(**params, device=device).to(device)\n",
    "model_bert.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '\"mr', 'dingle', 'the', 'strong\"', 'is', 'episode', '55', 'of', 'the', 'american', 'television', 'anthology', 'series', 'the', 'twilight', 'zone', 'it', 'originally', 'aired', 'on', 'march', '3', '1961', 'on', 'cbs', 'opening', 'narration', 'the', 'narration', 'continues', 'when', 'the', 'martians', 'arrive', 'plot', 'in', 'an', 'experiment', 'a', 'twoheaded', 'martian', 'scientist', 'who', 'is', 'invisible', 'to', 'earthlings', 'gives', 'vacuumcleaner', 'salesman', 'and', 'perennial', 'loser', 'luther', 'dingle', 'superhuman', 'strength', 'after', 'discovering', 'his', 'inexplicable', 'powers', 'dingle', 'begins', 'performing', 'various', 'feats', 'of', 'strength', 'from', 'lifting', 'statues', 'to', 'splitting', 'boulders', 'and', 'gains', 'a', 'great', 'deal', 'of', 'publicity', 'the', 'twoheaded', 'martian', 'returns', 'and', 'is', 'disappointed', 'to', 'see', 'that', 'dingle', 'is', 'using', 'his', 'strength', 'only', 'for', 'show', 'the', 'martian', 'takes', 'his', 'strength', 'away', 'just', 'as', 'dingle', 'attempts', 'to', 'lift', 'a', 'building', 'before', 'a', 'live', 'television', 'audience', 'unable', 'to', 'make', 'good', 'on', 'his', 'claims', 'or', 'repeat', 'any', 'of', 'his', 'previous', 'feats', 'dingle', 'becomes', 'a', 'laughingstock', 'as', 'the', 'twoheaded', 'martian', 'scientist', 'leaves', 'it', 'meets', 'two', 'venusians', 'who', 'are', 'also', 'searching', 'for', 'a', 'suitable', 'earthling', 'for', 'an', 'experiment', 'the', 'twoheaded', 'martian', 'scientist', 'recommends', 'dingle', 'and', 'the', 'venusians', 'gives', 'dingle', 'superintelligence', 'discovering', 'his', 'new', 'powers', 'dingle', 'starts', 'thinking', 'aloud', 'at', 'an', 'alarming', 'rate', 'and', 'demonstrates', 'incredible', '[MASK]', 'of', 'prediction', 'closing', 'narration', 'short', 'story', 'adaptation', 'in', 'the', 'short', 'story', 'version', 'of', 'this', 'episode', 'the', 'bettor', 'is', 'named', 'hubert', 'kransky', 'and', 'the', 'twoheaded', 'martian', 'is', 'named', 'xurthya', 'dingle', 'also', 'beats', 'up', 'hubert', 'at', 'one', 'point', 'additionally', 'dingle', 'takes', 'his', 'brilliance', 'to', 'change', 'the', 'world', 'at', 'harvard', 'see', 'also', 'list', 'of', 'the', 'twilight', 'zone', '(1959', 'tv', 'series)', 'episodes', 'references', 'devoe', 'bill', '(2008)', 'trivia', 'from', 'the', 'twilight', 'zone', 'albany', 'ga:', 'bear', 'manor', 'media', 'grams', 'martin', '(2008)', 'the', 'twilight', 'zone:', 'unlocking', 'the', 'door', 'to', 'a', 'television', 'classic', 'churchville', 'md:', 'otr', 'publishing', 'external', 'links', '1961', 'american', 'television', 'episodes', 'the', 'twilight', 'zone', '(1959', 'tv', 'series', 'season', '2)', 'episodes', 'television', 'episodes', 'written', 'by', 'rod', 'serling', '[SEP]', '\"the', 'prime', 'mover\"', 'is', 'episode', '57', 'of', 'the', 'american', 'television', 'anthology', 'series', 'the', 'twilight', 'zone', 'it', 'originally', 'aired', 'on', 'march', '24', '1961', 'on', 'cbs', 'opening', 'narration', 'plot', 'smalltime', 'gambler', 'ace', 'larsen', 'discovers', 'that', 'his', 'partner', 'jimbo', 'cobb', 'has', 'telekinetic', 'powers', 'after', 'a', 'car', 'overturns', 'outside', 'their', 'café', 'and', 'jimbo', 'moves', 'the', 'car', 'without', 'touching', 'it', 'ace', 'plans', 'to', 'use', \"jimbo's\", 'powers', 'to', 'win', 'big', 'in', 'las', 'vegas', 'and', 'he', 'takes', 'his', 'girlfriend', 'kitty', 'with', 'them', 'ace', 'wins', 'many', 'jackpots', 'disregarding', \"jimbo's\", 'headaches', 'from', 'the', 'use', 'of', 'his', 'powers', 'and', 'his', 'growing', 'moral', 'concerns', 'over', 'what', 'they', 'are', 'doing', 'kitty', 'is', 'repulsed', 'and', 'leaves', 'so', 'ace', 'uses', 'his', 'newly', 'acquired', 'cash', 'to', 'lure', 'the', 'attention', 'of', 'the', \"casino's\", 'cigarette', 'girl', 'and', 'bets', 'the', 'pile', 'in', 'a', 'game', 'of', 'craps', 'just', 'as', \"jimbo's\", 'powers', 'appear', 'to', '\"run', 'out\"', 'the', 'loss', 'awakens', 'ace', 'to', 'the', 'reality', 'of', 'what', 'he', 'has', 'become', 'and', 'he', 'and', 'jimbo', 'have', 'a', 'good', 'laugh', 'over', 'their', 'misfortune', 'the', 'three', 'return', 'home', 'and', 'back', 'at', 'the', 'café', 'ace', 'asks', 'kitty', 'to', 'marry', 'him', 'just', 'as', 'jimbo', 'drops', 'his', 'broom', 'she', 'flips', 'a', 'coin', 'and', 'ace', 'calls', '\"heads\"', 'kitty', \"doesn't\", 'show', 'ace', 'the', 'coin', 'or', 'tell', 'him', 'the', 'result', 'of', 'the', 'coin', 'toss;', 'kitty', 'simply', 'accepts', 'his', 'proposal', 'as', 'they', 'embrace', 'jimbo', 'picks', 'up', 'the', 'broom', 'telekinetically', 'revealing', 'he', 'faked', 'his', 'loss', 'of', 'power', 'to', 'snap', 'ace', 'out', 'of', 'his', 'greed', 'closing', 'narration', 'cast', 'dane', 'clark', 'as', 'ace', 'larsen', 'buddy', 'ebsen', 'as', 'jimbo', 'cobb', 'jane', 'burgess', 'as', 'sheila', 'christine', 'white', 'as', 'kitty', '[MASK]', 'william', 'keene', 'as', 'desk', 'clerk', 'nesdon', 'booth', 'as', 'big', 'phil', 'nolan', 'clancy', 'cooper', 'as', 'trucker', 'production', 'the', 'crash', 'scene', 'reuses', 'footage', 'from', 'the', '1958', 'film', 'thunder', 'road', 'see', 'also', 'list', 'of', 'the', 'twilight', 'zone', '(1959', 'tv', 'series)', 'episodes', 'references', 'devoe', 'bill', '(2008)', 'trivia', 'from', 'the', 'twilight', 'zone', 'albany', 'ga:', 'bear', 'manor', 'media', 'grams', 'martin', '(2008)', 'the', 'twilight', 'zone:', 'unlocking', 'the', 'door', 'to', 'a', 'television', 'classic', 'churchville', 'md:', 'otr', 'publishing', 'external', 'links', '1961', 'american', 'television', 'episodes', 'the', 'twilight', 'zone', '(1959', 'tv', 'series', 'season', '2)', 'episodes', 'television', 'shows', 'written', 'by', 'charles', 'beaumont', 'television', 'episodes', 'about', 'telekinesis', 'television', 'episodes', 'written', 'by', 'george', 'clayton', 'johnson', 'television', 'episodes', 'set', 'in', 'las', 'vegas', '[SEP]']\n",
      "masked tokens (words) :  ['them', 'and', 'powers', 'cavanaugh', 'md:']\n",
      "masked tokens list :  [307395, 150880, 203629, 305304, 84104]\n",
      "masked tokens (words) :  ['the', 'the', 'the', 'the', 'the']\n",
      "predict masked tokens list :  [153988, 153988, 153988, 153988, 153988]\n",
      "0\n",
      "isNext :  True\n",
      "predict isNext :  False\n"
     ]
    }
   ],
   "source": [
    "# Predict mask tokens ans isNext\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(batch[1]))\n",
    "print([id2word[w.item()] for w in input_ids[0] if id2word[w.item()] != '[PAD]'])\n",
    "input_ids = input_ids.to(device)\n",
    "segment_ids = segment_ids.to(device)\n",
    "masked_tokens = masked_tokens.to(device)\n",
    "masked_pos = masked_pos.to(device)\n",
    "isNext = isNext.to(device)\n",
    "\n",
    "logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)\n",
    "#logits_lm:  (1, max_mask, vocab_size) ==> (1, 5, 34)\n",
    "#logits_nsp: (1, yes/no) ==> (1, 2)\n",
    "\n",
    "#predict masked tokens\n",
    "#max the probability along the vocab dim (2), [1] is the indices of the max, and [0] is the first value\n",
    "logits_lm = logits_lm.data.cpu().max(2)[1][0].data.numpy() \n",
    "#note that zero is padding we add to the masked_tokens\n",
    "print('masked tokens (words) : ',[id2word[pos.item()] for pos in masked_tokens[0]])\n",
    "print('masked tokens list : ',[pos.item() for pos in masked_tokens[0]])\n",
    "print('masked tokens (words) : ',[id2word[pos.item()] for pos in logits_lm])\n",
    "print('predict masked tokens list : ', [pos for pos in logits_lm])\n",
    "\n",
    "#predict nsp\n",
    "logits_nsp = logits_nsp.cpu().data.max(1)[1][0].data.numpy()\n",
    "print(logits_nsp)\n",
    "print('isNext : ', True if isNext else False)\n",
    "print('predict isNext : ',True if logits_nsp else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying a bigger dataset should be able to see the difference."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
